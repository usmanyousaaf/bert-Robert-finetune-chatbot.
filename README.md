# Chatbot Finetuning with BERT and RoBERTa

This project focuses on finetuning BERT and RoBERTa models to enhance chatbot performance. The aim is to compare the accuracy and efficiency of these two pre-trained models in a conversational AI context. The chatbot app allows users to ask questions and choose between the BERT and RoBERTa models to get responses, providing a practical demonstration of the models' capabilities.

## Features

- **Model Selection**: Choose between BERT and RoBERTa models for generating responses.
- **Real-time Interaction**: Ask questions and receive answers instantly.
- **Performance Comparison**: Analyze and compare the accuracy of responses from both models.

## Installation

1. Clone the repository:
    ```bash
    git clone https://github.com/your-username/chatbot-finetuning.git
    cd chatbot-finetuning
    ```

2. Install the required dependencies:
    ```bash
    pip install -r requirements.txt
    ```

3. Run the Streamlit app:
    ```bash
    streamlit run app.py
    ```

## Usage

- Open the app in your browser.
- Type your question in the input field.
- Select either the BERT or RoBERTa model.
- View the response and the question history.

## Accuracy and Performance Analysis

We have conducted extensive testing and evaluation of both BERT and RoBERTa models. The results of our analysis, including accuracy metrics and performance benchmarks, are documented in our published paper. This paper is available in the `docs` folder of this repository.

## Screenshot

![Screenshot from 2023-10-19 21-25-16](https://github.com/user-attachments/assets/9f5ed316-3b80-4636-8370-824164a7e28a)

![Screenshot from 2023-10-19 21-25-39](https://github.com/user-attachments/assets/991001f0-a85e-4ce4-9028-646cdd85678a)

## Contributing

We welcome contributions from the community. Please feel free to submit issues, feature requests, and pull requests.

### Contributors

- [Usman Yousaf](https://github.com/usmanyousaaf)
- [Haseeb Wajid](https://github.com/Hasibwajid)

## License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.

## Acknowledgments

Special thanks to the developers and contributors of the BERT and RoBERTa models.
